{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56b9f698-4921-4efc-83a8-f66f941a9ca5",
   "metadata": {},
   "source": [
    "# Automated Calbration using the all new Python Interface!\n",
    "\n",
    "We are excited to announce our newly developed C++ based calibration library that offers python bindings for seamless calibration automation. The library provides the same functionality as the camcalib GUI but without the need for any manual interaction. You simply specify the sensors and calibration modalities (either via yaml files or directly in python code) and the software does the rest. It is the ideal tool for calibration automation, or to build you calibration workflow on top. This release addresses the need for more efficiency and flexibility in multi modal sensor calibration processes. \n",
    "\n",
    "The installation is as easy as installing the pip wheel and you are ready to go. \n",
    "\n",
    "- We currently support Ubuntu 20.04 (with python3.8) and Ubuntu 22.04 (with python3.10).\n",
    "- Data can either be provided as rosbags or image/point cloud files.\n",
    "- Find out more in this blog post about how and what!\n",
    "\n",
    "## Motivation\n",
    "In the fast-evolving world of robotics, deploying sensor systems in unknown environments presents a significant challenge. Ensuring these sensors are properly calibrated is crucial to maximize the uptime and efficiency of robot fleets. Recognizing this need, we are thrilled to announce the release of our multimodal calibration library, now featuring Python bindings. This powerful library is designed to help robotic OEMs (Original Equipment Manufacturers) and integrators develop user-friendly, in-field calibration tools tailored to their customers' specific needs and robotic systems. With support for various sensor types, an intuitive interface, and the flexibility to create custom calibration routines, our library ensures precise sensor performance and optimal robot functionality. By leveraging this tool, our partners can provide advanced, reliable, and easy-to-use calibration solutions, ensuring their robotic systems perform at their best in any environment. We are excited to see the innovative solutions that will emerge from this release and the positive impact it will have on the robotics industry.\n",
    "\n",
    "## Key Benefits\n",
    "\n",
    "### 1. Streamlined Workflows:\n",
    "- Automate repetitive calibration tasks.\n",
    "- Integrate calibrations seamlessly into your existing systems and pipelines.\n",
    "- Set your own thresholds and quality criterias to and directly react to outliers or suspicious results.\n",
    "\n",
    "### 2. Enhanced Flexibility:\n",
    "- Use Python scripts to control the calibration process, making it accessible for those familiar with Python.\n",
    "- Leverage the speed and efficiency of the C++ backend for demanding applications.\n",
    "\n",
    "### 3. No GUI Required:\n",
    "- Run calibrations on headless servers or remote machines.\n",
    "- Perfect for batch processing and large datasets.\n",
    "\n",
    "## Real-World Applications\n",
    "The library can help you streamline a variety of real-world applications, such as\n",
    "- **Automated Manufacturing** and **End-of-Line Calibration**: Integrate the calibration process directly into the production line for real-time quality control.\n",
    "- **Robotics**: Calibrate sensors on-the-fly in dynamic environments without manual intervention.\n",
    "- **Research**: Process large datasets efficiently, freeing up valuable time for analysis and innovation.\n",
    "\n",
    "## Currently Supported Sensor Types and Calibration Targets\n",
    "- We currently support the following sensors\n",
    "  - Camera (with the following distortion models):\n",
    "    - Pinhole\n",
    "    - PinholeRadTan4/5/8\n",
    "    - KannalaBrandt/Fisheye)\n",
    "  - IMU\n",
    "  - 3D Lidar\n",
    "- We currently support the board types\n",
    "  - Checkerboard\n",
    "  - [Aprilgrid](https://github.com/ethz-asl/kalibr/wiki/calibration-targets)\n",
    "  - April-Checkerboard (custom in-house developed)\n",
    "  - Random-Dot\n",
    "  - [Charuco](https://docs.opencv.org/4.x/df/d4a/tutorial_charuco_detection.html)\n",
    "  - [Radon](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#gadc5bcb05cb21cf1e50963df26986d7c9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beae837-b5b4-4a72-a9be-2cfb308bc1be",
   "metadata": {},
   "source": [
    "## Supported Platforms\n",
    "- Ubuntu 20.04 LTS (Python 3.8)\n",
    "- Ubuntu 22.04 LTS (Python 3.10)\n",
    "- Ubuntu 24.04 LTS (Python 3.12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508fd76-d92e-4439-8608-e3d91227b554",
   "metadata": {},
   "source": [
    "## Straight-Forward Installation\n",
    "Simply install the pip wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d82be-1a54-4bfb-9f43-0561b240105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install camcalib.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19323d3c-18fa-445f-8690-29fe16733ec0",
   "metadata": {},
   "source": [
    "## Easy to Use\n",
    "A minimal working example follows, at first import camcalib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21076f59-2d12-4bb1-b392-cdfc0480c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import camcalib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26c07e-5faa-4d81-addb-d9387d7c57bb",
   "metadata": {},
   "source": [
    "Then define the calibration pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005d7b5e-ff79-4105-a671-23fed2a3e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = camcalib.targets.AprilBoard(6, 6, 0.08, 0.3, \"A36h11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71443a3a-8d1b-421b-9c40-8c45971fed5f",
   "metadata": {},
   "source": [
    "Load calibration data, either from folders on the filesystem or like here from a ROS1 bag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6163c496-99c0-4a01-b833-df6d8bdeea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n",
      "\n",
      "/camera2/infra1/image_rect_raw: found 5880 corners in 300 frames\n"
     ]
    }
   ],
   "source": [
    "calib_data = camcalib.calibration.CalibrationData()\n",
    "calib_data.set_target(target)\n",
    "calib_data.from_bag('sample.bag')\n",
    "sensors = camcalib.calibration.CalibrationResult.load('sensors.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab25e1c-1e2f-4f59-a651-bfb71991057b",
   "metadata": {},
   "source": [
    "Start the calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c14de74-5028-47d8-a1d1-aaf33c67698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [2024-08-27T14:47:54Z] [initialize_intrinsics]: Available Camera Data: [/camera2/infra1/image_rect_raw]\n",
      "[INFO] [2024-08-27T14:47:54Z] [initialize_intrinsics]: Initializing intrinsics of camera /camera2/infra1/image_rect_raw\n",
      "[INFO] [2024-08-27T14:47:55Z] [initialize_intrinsics]: Initial error: 0.193515\n",
      "[INFO] [2024-08-27T14:47:55Z] [initialize_parameters]: Initialize intrinsic time: 0.242890\n",
      "[INFO] [2024-08-27T14:47:55Z] [initialize_extrinsics]: Initializing extrinsics of camera /camera2/infra1/image_rect_raw\n",
      "[INFO] [2024-08-27T14:47:55Z] [initialize_extrinsics]: Use 5792 features for camera /camera2/infra1/image_rect_raw\n",
      "[INFO] [2024-08-27T14:47:55Z] [initialize_parameters]: Initialize extrinsic time: 0.037915\n",
      "[INFO] [2024-08-27T14:47:55Z] [calibrate]: Build problem time: 0.001369\n",
      "[INFO] [2024-08-27T14:47:55Z] [calibrate]: Added 230 residuals.\n",
      "[INFO] [2024-08-27T14:47:55Z] [calibrate]: Solving for 466 parameters.\n",
      "[INFO] [2024-08-27T14:47:55Z] [calibrate]: Calibrating sensors: [/camera2/infra1/image_rect_raw]\n",
      "[INFO] [2024-08-27T14:47:55Z] [solve]: Initial RMSE: 1.308165\n",
      "[INFO] [2024-08-27T14:47:55Z] [solve]: [=                        ]: error: 0.337589\n",
      "Results:\n",
      "\tCameras\n",
      "\t\t/camera2/infra1/image_rect_raw: Pinhole(dt: 0, [647.776, 648.674, 643.455, 401.331] +/- [0.368634 0.294748 0.141858 0.311276])\n",
      "\tSensor extrinsics\n",
      "\t\t(/camera2/infra1/image_rect_raw <- base): Pose(r: [0, 0, 0], t: [0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with camcalib.calibration.CalibratorSession() as cc:\n",
    "    cc.add_calibration_data(calib_data)\n",
    "    cc.add_calibration(sensors)\n",
    "    results, summary = cc.calibrate()\n",
    "    results.save('calibration.yaml')\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6d706-e055-4856-9c4a-e86490ed6e58",
   "metadata": {},
   "source": [
    "Which gives us the intrinsics of the camera and the identity as extrinsics since it's the only sensor we calibrated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
